{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "from transformers import get_scheduler\n",
    "\n",
    "##### Own\n",
    "from train_utils import make_optimizer\n",
    "from vision_transformer import VisionTransformer\n",
    "from train_utils import cifar_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 4\n",
    "# cifar = load_dataset(\"uoft-cs/cifar100\")\n",
    "# train_label_type = \"coarse\" # cfg[\"dataset\"][\"train_label_type\"]\n",
    "\n",
    "# train_dataloader, test_dataloader = cifar_utils.dataloader_from_dataset_dict(cifar, batch_size=batch_size)\n",
    "# label2id_coarse, id2label_coarse = cifar_utils.get_cifar_label_dicts(cifar, train_label_type)\n",
    "\n",
    "# model = VisionTransformer(\n",
    "#         image_size=32, use_linear_patch=True, num_classes=len(label2id_coarse.keys()))\n",
    "\n",
    "# num_epochs = 3 # TODO: set a param in the config file\n",
    "# lr = 0.003\n",
    "# num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "# optimizer = make_optimizer(optimizer_name='adamw',model=model, lr=0.003)\n",
    "# lr_scheduler = get_scheduler(\n",
    "# name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    "# )\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "cifar_small = load_dataset(\"uoft-cs/cifar100\", split=\"train[:10]\")\n",
    "train_label_type = \"coarse\" # cfg[\"dataset\"][\"train_label_type\"]\n",
    "\n",
    "# train_dataloader, test_dataloader = cifar_utils.dataloader_from_dataset_dict(cifar, batch_size=batch_size)\n",
    "train_dataloader= cifar_utils.dataloader_from_dataset(cifar_small, batch_size=batch_size)\n",
    "label2id_coarse, id2label_coarse = cifar_utils.get_cifar_label_dicts(cifar_small, train_label_type)\n",
    "\n",
    "model = VisionTransformer(\n",
    "        image_size=32, use_linear_patch=True, num_classes=len(label2id_coarse.keys()))\n",
    "\n",
    "num_epochs = 1 # TODO: set a param in the config file\n",
    "lr = 0.003\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "\n",
    "optimizer = make_optimizer(optimizer_name='adamw',model=model, lr=0.003)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    "    )\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single epoch training loop\n",
    "model.train()\n",
    "epoch_train_loss = 0\n",
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    # transfer batch to device\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "    # forward pass and loss calculation\n",
    "    outputs = model(batch[\"pixel_values\"])\n",
    "    loss = loss_function(outputs, batch[\"coarse_label\"])\n",
    "    loss.backward()\n",
    "    epoch_train_loss += loss.item()\n",
    "\n",
    "    # backward pass\n",
    "    optimizer.step()\n",
    "    lr_scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "epoch_train_loss/=len(train_dataloader)\n",
    "\n",
    "# logger.info(f'Validating at epoch {epoch}')\n",
    "epoch_val_loss = 0\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    total_examples, correct_predictions= 0.0, 0.0\n",
    "    for batch_idx, batch in enumerate(train_dataloader):\n",
    "        # transfer batch to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(batch[\"pixel_values\"])\n",
    "        \n",
    "        epoch_val_loss += loss_function(outputs, batch[\"coarse_label\"]).item() # retrieve only the scalar value\n",
    "        pred_labels = outputs.argmax(dim=1)\n",
    "        \n",
    "        total_examples += float(len(batch['coarse_label']))\n",
    "        correct_predictions += float((batch[\"coarse_label\"] == pred_labels).sum().item())\n",
    "\n",
    "    acc = correct_predictions / total_examples\n",
    "    epoch_val_loss /= len(train_dataloader)\n",
    "\n",
    "    print(f'-- train loss {train_loss:.3f} -- validation accuracy {acc:.3f} -- validation loss: {epoch_val_loss:.3f}')\n",
    "    if epoch_val_loss <= best_val_loss and save_model:\n",
    "        torch.save(model.state_dict(), 'model.pth')\n",
    "        best_val_loss = epoch_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_val_loss = 0\n",
    "correct_predictions = 0\n",
    "# model = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: torch.Size([2, 3, 32, 32])\n",
      "batch labels: tensor([11,  4], device='cuda:0')\n",
      "outputs: torch.Size([2, 20])\n",
      "loss: 2.995732307434082\n",
      "pred_labels: tensor([ 1., 11.], device='cuda:0')\n",
      "correct: 0\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "batch = next(iter(train_dataloader))\n",
    "batch = {k: v.to(device) for k, v in batch.items()}\n",
    "print(f\"batch_size: {batch['pixel_values'].shape}\")\n",
    "print(f\"batch labels: {batch['coarse_label']}\")\n",
    "\n",
    "outputs = model(batch[\"pixel_values\"])\n",
    "\n",
    "loss = loss_function(outputs, batch[\"coarse_label\"])\n",
    "epoch_val_loss += loss.item() # retrieve only the scalar value\n",
    "pred_labels = outputs.argmax(dim=1)\n",
    "\n",
    "print(f\"outputs: {outputs.shape}\")\n",
    "print(f\"loss: {loss}\")\n",
    "print(f\"pred_labels: {pred_labels}\")\n",
    "\n",
    "correct_predictions += int((batch[\"coarse_label\"] == pred_labels).sum().item())\n",
    "print(f\"correct: {correct_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for batch_idx, batch in enumerate(train_dataloader):\n",
    "    print(batch[\"coarse_label\"])\n",
    "    if batch_idx > 2:\n",
    "        break\n",
    "# batch = next(iter(train_dataloader))\n",
    "# # print((batch))\n",
    "# outputs = model(batch[\"pixel_values\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lgvit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
